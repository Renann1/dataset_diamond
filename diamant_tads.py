# -*- coding: utf-8 -*-
"""diamant_TADS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10B1HM44u083vgILmG3rnfckWJAXjzDZv

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/storopoli/ciencia-de-dados/master?filepath=notebooks%2FAtividade_TADS.ipynb)
<br>
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/storopoli/ciencia-de-dados/blob/master/notebooks/Atividade_TADS.ipynb)

# Atividade TADS

Nesta atividadade que, conforme orientação da coordenação, vale 60% da média do aluno, o objetivo é **desenvolver e treinar um algoritmo de regressão linear** para prever o preço de um diamante.

Lembrando que preço é uma variável quantitativa, portanto estamos em um problema de aprendizagem supervisionada de regressão.

## Sobre o Dataset Diamonds

O dataset diamonds foi baixado pelo Kaggle e pode ser encontrado neste [link](https://www.kaggle.com/shivam2503/diamonds). Está em formato de valores separados por vírgula (`.CSV`).

Ele possui as seguintes variáveis:
* `carat` peso do diamante em quilates
* `cut` qualidade do corte do diamante
* `color` cor do diamante
* `clarity` uma medida de transparência do diamante
* `depth` profundidade total em pontos percentuais
* `table` largura do topo do diamante relativo ao seu ponto mais largo
* **`price`: preço em dólares do diamante**
* `x` comprimento em milímetros
* `y` largura em milímetros
* `z` profundidade em milímetros

## Etapas da Atividade

1. Importar o dataset no pandas (`pd.read_csv`):
  1. se atentar com os `index_col`.
  2. especificar os `dtypes` -- tem muita variável qualitativa nesse dataset. Usar o argumento `dtype` do `pd.read_csv` que aceita um dicionário. Ver a documentação do pandas.

2. Calcular algumas estatísticas dos dados com pandas `groupby`:
  1. Média e Mediana do `price` por `cut`
    * Guardar em variáveis: `mean_price_cut` e `median_price_cut`.
  2. Média e Mediana do `carat` por `color`
    * Guardar em variáveis: `mean_carat_color` e `median_carat_color`.

3. Fazer alguns gráficos dos dados com o matplotlib.pyplot (Obs: pode usar direto a API do pandas para gráficos `Pd.plot`):
  1. Histograma `hist` da variável `price`. Adicionar um título com `plt.title()` e adicionar os rótulos do eixo X e Y `plt.xlab()` e `plt.ylabel()`.
  2. Gráfico de barras `bar` da variável `cut` (cuidado com o `Pd.Series.value_counts()`). Adicionar um título com `plt.title()` e adicionar os rótulos do eixo X e Y `plt.xlab()` e `plt.ylabel()`.

4. Preparar os dados para o Scikit-Learn
  1. Codificar as variáveis qualitativas `cut`, `color` e `clarity` com dummies (OBS: atividade já realizada, inserida apenas para aprendizagem)
  2. Criar o dataset `X` com todas as variáveis do `df_final` **menos** `price`.
  3. Criar a resposta `y` **somente** com `price`.
  4. Quebrar em dados de treino e de teste com o `train_test_split`. Usar o padrão `test_size = 0.25`. **Não passar seed** no `random_state` pois estamos já setando uma global com o `np.random.seed`.

5. Treinar um modelo `LinearRegression` do Scikit-Learn para prever o `price` do diamante:
  1. Reportar o erro absoluto médio `mean_absolute_error` do seu modelo nos dados de treino e dados de teste. Guardar em variáveis `mae_train` e `mae_test`.
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error

# %matplotlib inline

# Importante não mudar essa seed pois sua atividade será avaliada baseada nos resultados dessa seed
np.random.seed(123)

# 1. Importar no Pandas
df = pd.read_csv('https://github.com/storopoli/ciencia-de-dados/raw/master/notebooks/data/diamonds.csv',
                 index_col=0,
                 dtype=({'price':float, 'cut':'category', 'clarity':'category'}))

df.info()

df

# 2. Groupbys
mean_price_cut = df['price'].groupby(df['cut']).mean()
median_price_cut = df['price'].groupby(df['cut']).median()
mean_carat_color = df['carat'].groupby(df['color']).mean()
median_carat_color = df['carat'].groupby(df['color']).median()

print(mean_price_cut)
print(median_price_cut)
print(mean_carat_color)
print(median_carat_color)

# 3. Plots
plt.style.use('ggplot')
import matplotlib.pyplot as plt
df['price'].plot(kind = 'hist', color ='b')
plt.title('Diamante', color ='b')
plt.xlabel('price', color = 'black')
plt.ylabel('rare', color = 'b')

df['cut'].value_counts().plot(kind = 'bar', color =['b','black'])
plt.title('Corte', color ='black')
plt.xlabel('cut', color ='b')
plt.ylabel('AmountDiamonds', color ='b')

# 4. Pré-processamento Scikit-Learn
df_final = pd.get_dummies(df, columns=['cut', 'color', 'clarity'])

X = df_final.drop('price', axis=1).to_numpy()
y = df_final['price'].to_numpy()

print(X.shape)
print(y.shape)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)

# 5. Treinamento do Modelo
clf = LinearRegression()
clf.fit(X_train, y_train)

y_pred_train = clf.predict(X_train)
mae_train = mean_absolute_error(y_pred_train, y_train)

y_pred_test = clf.predict(X_test)
mae_test = mean_absolute_error(y_pred_test, y_test)

print(f"MAE Treino: {mae_train}")
print(f"MAE Teste: {mae_test}")

from numpy.testing import assert_approx_equal

# Groupbys
assert_approx_equal(mean_price_cut['Good'], 3928.8644)
assert_approx_equal(median_price_cut['Fair'], 3282)
assert_approx_equal(mean_carat_color['D'], 0.657794833)
assert_approx_equal(median_carat_color['H'], 0.9)

# MAEs
assert_approx_equal(mae_train, 739.279089)
assert_approx_equal(mae_test, 742.526558)